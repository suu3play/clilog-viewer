#!/usr/bin/env python3
"""
ä¼šè©±ãƒ­ã‚°ã‚’Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import json
import re
from datetime import datetime, timezone, timedelta
from pathlib import Path
import configparser
import os
import getpass


def format_timestamp(timestamp_str):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’JSTå½¢å¼ã«å¤‰æ›"""
    try:
        # UTCæ™‚åˆ»ã‚’ãƒ‘ãƒ¼ã‚¹
        dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        
        # JSTã«å¤‰æ›ï¼ˆUTC+9ï¼‰
        jst = timezone(timedelta(hours=9))
        dt_jst = dt.astimezone(jst)
        
        return dt_jst.strftime('%Y-%m-%d %H:%M:%S JST')
    except:
        return timestamp_str


def parse_message_date(timestamp_str):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ—¥ä»˜ã‚’è§£æã—ã¦datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™"""
    try:
        # UTCæ™‚åˆ»ã‚’ãƒ‘ãƒ¼ã‚¹
        dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        return dt
    except:
        return None


class DateFilter:
    """æ—¥ä»˜ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ã‚¯ãƒ©ã‚¹"""
    def __init__(self, start_date=None, end_date=None):
        self.start_date = self._parse_date(start_date) if start_date else None
        self.end_date = self._parse_date(end_date) if end_date else None
        
        # çµ‚äº†æ—¥ã¯23:59:59ã¾ã§å«ã‚ã‚‹
        if self.end_date:
            self.end_date = self.end_date.replace(hour=23, minute=59, second=59, microsecond=999999)
    
    def _parse_date(self, date_str):
        """æ—¥ä»˜æ–‡å­—åˆ—ã‚’datetimeã«å¤‰æ›ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰"""
        try:
            if isinstance(date_str, str):
                # YYYY-MM-DDå½¢å¼ã‚’æƒ³å®š
                dt = datetime.strptime(date_str, '%Y-%m-%d')
                # UTCã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’è¨­å®š
                return dt.replace(tzinfo=timezone.utc)
            elif isinstance(date_str, datetime):
                return date_str
            else:
                return None
        except ValueError:
            print(f"è­¦å‘Š: æ—¥ä»˜å½¢å¼ãŒç„¡åŠ¹ã§ã™: {date_str}")
            return None
    
    def is_in_range(self, message_date):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ—¥ä»˜ãŒç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯"""
        if not isinstance(message_date, datetime):
            return True  # æ—¥ä»˜ãŒä¸æ˜ãªå ´åˆã¯å«ã‚ã‚‹
        
        # é–‹å§‹æ—¥ã®ãƒã‚§ãƒƒã‚¯
        if self.start_date and message_date < self.start_date:
            return False
        
        # çµ‚äº†æ—¥ã®ãƒã‚§ãƒƒã‚¯
        if self.end_date and message_date > self.end_date:
            return False
        
        return True
    
    def is_active(self):
        """ãƒ•ã‚£ãƒ«ã‚¿ãŒæœ‰åŠ¹ã‹ã©ã†ã‹"""
        return self.start_date is not None or self.end_date is not None


def extract_content(message):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º"""
    if isinstance(message, dict):
        if 'content' in message:
            content = message['content']
            if isinstance(content, list):
                text_parts = []
                for item in content:
                    if isinstance(item, dict) and item.get('type') == 'text':
                        text_parts.append(item.get('text', ''))
                    elif isinstance(item, dict) and item.get('type') == 'tool_use':
                        tool_name = item.get('name', 'unknown')
                        tool_input = item.get('input', {})
                        text_parts.append(f"[ãƒ„ãƒ¼ãƒ«ä½¿ç”¨: {tool_name}]\n```json\n{json.dumps(tool_input, ensure_ascii=False, indent=2)}\n```")
                return '\n'.join(text_parts)
            elif isinstance(content, str):
                return content
        elif 'role' in message:
            return extract_content(message)
    return str(message)


def clean_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    if not text:
        return ""
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†
    text = re.sub(r'<command-message>.*?</command-message>', '', text, flags=re.DOTALL)
    text = re.sub(r'<command-name>.*?</command-name>', '', text, flags=re.DOTALL)
    text = re.sub(r'<command-args>.*?</command-args>', '', text, flags=re.DOTALL)
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼ã®å‡¦ç†
    text = re.sub(r'<system-reminder>.*?</system-reminder>', '', text, flags=re.DOTALL)
    
    # ç©ºè¡Œã®æ•´ç†
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    text = text.strip()
    
    return text


def process_log_line(line, date_filter=None):
    """ãƒ­ã‚°ã®1è¡Œã‚’å‡¦ç†"""
    try:
        data = json.loads(line.strip())
        
        # åŸºæœ¬æƒ…å ±ã®æŠ½å‡º
        timestamp = data.get('timestamp', '')
        user_type = data.get('userType', data.get('type', ''))
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if date_filter and timestamp:
            message_date = parse_message_date(timestamp)
            if message_date and not date_filter.is_in_range(message_date):
                return None
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã®æŠ½å‡º
        message_data = data.get('message', {})
        role = message_data.get('role', user_type)
        content = extract_content(message_data)
        
        # ã‚µãƒãƒªãƒ¼æƒ…å ±ã®å‡¦ç†
        if data.get('type') == 'summary':
            return {
                'timestamp': format_timestamp(timestamp),
                'type': 'summary',
                'content': data.get('summary', ''),
                'role': 'system'
            }
        
        # é€šå¸¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
        if content:
            content = clean_text(content)
            if content:  # ç©ºã§ãªã„å ´åˆã®ã¿è¿”ã™
                return {
                    'timestamp': format_timestamp(timestamp),
                    'type': 'message',
                    'role': role,
                    'content': content
                }
    
    except json.JSONDecodeError:
        # JSONä»¥å¤–ã®è¡Œã¯ç„¡è¦–
        pass
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"å•é¡Œã®ã‚ã‚‹è¡Œ: {line[:100]}...")
    
    return None


def generate_output_filename(input_file, output_directory, username=None):
    """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å_æ—¥ä»˜å½¢å¼ï¼‰"""
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ™‚åˆ»ã‚’å–å¾—ï¼ˆUTCï¼‰
    mod_time_utc = datetime.fromtimestamp(input_file.stat().st_mtime, tz=timezone.utc)
    
    # JSTã«å¤‰æ›
    jst = timezone(timedelta(hours=9))
    mod_time_jst = mod_time_utc.astimezone(jst)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å–å¾—ï¼ˆæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç«¯æœ«ãƒ¦ãƒ¼ã‚¶ãƒ¼åï¼‰
    if username is None:
        try:
            username = getpass.getuser()
        except Exception:
            username = "unknown"
    
    timestamp = mod_time_jst.strftime('%Y%m%d%H%M%S')
    filename = f"log_{username}_{timestamp}_{input_file.stem}.md"
    return output_directory / filename


def load_processed_files_info(info_file):
    """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’èª­ã¿è¾¼ã¿"""
    if not info_file.exists():
        return {}
    
    try:
        with open(info_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        return {}


def save_processed_files_info(info_file, info):
    """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ä¿å­˜"""
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(info, f, indent=2)


def should_process_file(input_file, processed_info):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã¹ãã‹ãƒã‚§ãƒƒã‚¯"""
    file_key = input_file.name
    current_mtime = input_file.stat().st_mtime
    
    if file_key in processed_info:
        last_mtime = processed_info[file_key].get('mtime', 0)
        if current_mtime <= last_mtime:
            return False
    
    return True


def convert_log_to_markdown(input_file, output_file=None, date_filter=None):
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Markdownã«å¤‰æ›"""
    if output_file is None:
        output_file = Path(input_file).with_suffix('.md')
    
    messages = []
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    processed = process_log_line(line, date_filter)
                    if processed:
                        messages.append(processed)
    except FileNotFoundError:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
        return False
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    if not messages:
        print("å¤‰æ›å¯èƒ½ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return False
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# ä¼šè©±ãƒ­ã‚°\n\n")
            # ç”Ÿæˆæ—¥æ™‚ã‚’JSTã§è¡¨ç¤º
            jst = timezone(timedelta(hours=9))
            now_jst = datetime.now(jst)
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {now_jst.strftime('%Y-%m-%d %H:%M:%S JST')}\n\n")
            f.write("---\n\n")
            
            for msg in messages:
                timestamp = msg['timestamp']
                role = msg['role']
                content = msg['content']
                msg_type = msg.get('type', 'message')
                
                if msg_type == 'summary':
                    f.write(f"## ğŸ“‹ ã‚µãƒãƒªãƒ¼ ({timestamp})\n\n")
                    f.write(f"{content}\n\n")
                else:
                    # ãƒ­ãƒ¼ãƒ«è¡¨ç¤ºã®èª¿æ•´
                    if role == 'user':
                        role_display = "ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼"
                    elif role == 'assistant':
                        role_display = "ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
                    else:
                        role_display = f"âš™ï¸ {role}"
                    
                    f.write(f"## {role_display} ({timestamp})\n\n")
                    f.write(f"{content}\n\n")
                    f.write("---\n\n")
        
        print(f"å¤‰æ›å®Œäº†: {output_file}")
        print(f"å‡¦ç†ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(messages)}")
        return True
        
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False


class Config:
    """è¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹"""
    def __init__(self, config_file='log_converter_config.ini'):
        self.config_file = Path(config_file)
        self.config = configparser.ConfigParser()
        self.load_config()
    
    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if self.config_file.exists():
            self.config.read(self.config_file, encoding='utf-8')
        else:
            self.create_default_config()
    
    def create_default_config(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        self.config['DEFAULT'] = {
            'log_directory': '',  # ç©ºã®å ´åˆã¯è‡ªå‹•æ¤œç´¢
            'output_directory': '',  # ç©ºã®å ´åˆã¯ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            'username': '',  # ç©ºã®å ´åˆã¯ç«¯æœ«ãƒ¦ãƒ¼ã‚¶ãƒ¼å
            'max_files': '10',
            'skip_unchanged': 'true',
            'date_start': '',  # é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰
            'date_end': ''     # çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰
        }
        self.save_config()
        print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {self.config_file}")
    
    def save_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            self.config.write(f)
    
    def get_log_directory(self):
        """ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
        log_dir = self.config.get('DEFAULT', 'log_directory', fallback='')
        if log_dir:
            return Path(log_dir)
        return Path.home() / '.claude' / 'projects'
    
    def get_output_directory(self):
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
        output_dir = self.config.get('DEFAULT', 'output_directory', fallback='')
        if output_dir:
            return Path(output_dir)
        return Path.cwd()
    
    def get_max_files(self):
        """æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’å–å¾—"""
        return self.config.getint('DEFAULT', 'max_files', fallback=10)
    
    def get_skip_unchanged(self):
        """æœªå¤‰æ›´ã‚¹ã‚­ãƒƒãƒ—è¨­å®šã‚’å–å¾—"""
        return self.config.getboolean('DEFAULT', 'skip_unchanged', fallback=True)
    
    def get_username(self):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼åè¨­å®šã‚’å–å¾—"""
        username = self.config.get('DEFAULT', 'username', fallback='')
        if username:
            return username
        try:
            return getpass.getuser()
        except Exception:
            return "unknown"
    
    def get_date_filter(self):
        """æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿è¨­å®šã‚’å–å¾—"""
        start_date = self.config.get('DEFAULT', 'date_start', fallback='')
        end_date = self.config.get('DEFAULT', 'date_end', fallback='')
        
        if start_date or end_date:
            return DateFilter(start_date or None, end_date or None)
        return None
    
    def set_date_range(self, start_date, end_date):
        """æ—¥ä»˜ç¯„å›²ã‚’è¨­å®š"""
        self.config.set('DEFAULT', 'date_start', start_date or '')
        self.config.set('DEFAULT', 'date_end', end_date or '')
        self.save_config()


def find_log_files(log_directory=None):
    """Claudeãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé…ä¸‹ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    if log_directory is None:
        log_directory = Path.home() / '.claude' / 'projects'
    
    if not log_directory.exists():
        print(f"ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {log_directory}")
        return []
    
    jsonl_files = []
    for root, dirs, files in os.walk(log_directory):
        for file in files:
            if file.endswith('.jsonl'):
                full_path = Path(root) / file
                jsonl_files.append(full_path)
    
    # æ›´æ–°æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    jsonl_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return jsonl_files


def select_log_file(files):
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ"""
    if not files:
        print("JSONLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    
    if len(files) == 1:
        print(f"è¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«: {files[0]}")
        return files[0]
    
    print("è¤‡æ•°ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
    for i, file in enumerate(files, 1):
        rel_path = file.relative_to(Path.home() / '.claude' / 'projects')
        file_size = file.stat().st_size
        mod_time = datetime.fromtimestamp(file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
        print(f"{i:2d}: {rel_path} ({file_size:,} bytes, æ›´æ–°: {mod_time})")
    
    while True:
        try:
            choice = input("\né¸æŠã—ã¦ãã ã•ã„ (ç•ªå·): ").strip()
            if not choice:
                return None
            index = int(choice) - 1
            if 0 <= index < len(files):
                return files[index]
            else:
                print("ç„¡åŠ¹ãªç•ªå·ã§ã™ã€‚")
        except ValueError:
            print("æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        except KeyboardInterrupt:
            print("\nä¸­æ–­ã—ã¾ã—ãŸã€‚")
            return None


def process_multiple_files(files, config, processed_info, info_file, username=None, date_filter=None):
    """è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†"""
    processed_count = 0
    skipped_count = 0
    filtered_count = 0
    
    output_directory = config.get_output_directory()
    skip_unchanged = config.get_skip_unchanged()
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯è¨­å®šã‹ã‚‰å–å¾—
    if username is None:
        username = config.get_username()
    
    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯è¨­å®šã‹ã‚‰å–å¾—
    if date_filter is None:
        date_filter = config.get_date_filter()
    
    for file in files:
        if skip_unchanged and not should_process_file(file, processed_info):
            print(f"ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªå¤‰æ›´ï¼‰: {file.name}")
            skipped_count += 1
            continue
        
        output_file = generate_output_filename(file, output_directory, username)
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®è¡¨ç¤º
        if date_filter and date_filter.is_active():
            print(f"å‡¦ç†ä¸­ï¼ˆæ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ï¼‰: {file.name} â†’ {output_file.name}")
        else:
            print(f"å‡¦ç†ä¸­: {file.name} â†’ {output_file.name}")
        
        success = convert_log_to_markdown(file, output_file, date_filter)
        if success:
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            if output_file.exists() and output_file.stat().st_size > 100:  # ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿ã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                # å‡¦ç†æ¸ˆã¿æƒ…å ±ã‚’æ›´æ–°
                processed_info[file.name] = {
                    'mtime': file.stat().st_mtime,
                    'output_file': str(output_file),
                    'processed_at': datetime.now(timezone(timedelta(hours=9))).isoformat(),
                    'date_filter': f"{date_filter.start_date}~{date_filter.end_date}" if date_filter and date_filter.is_active() else None
                }
                processed_count += 1
            else:
                print(f"  â†’ æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ã«ã‚ˆã‚Šé™¤å¤–ã•ã‚Œã¾ã—ãŸ")
                filtered_count += 1
                # ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤
                if output_file.exists():
                    output_file.unlink()
        else:
            print(f"ã‚¨ãƒ©ãƒ¼: {file.name} ã®å‡¦ç†ã«å¤±æ•—")
    
    # å‡¦ç†æ¸ˆã¿æƒ…å ±ã‚’ä¿å­˜
    save_processed_files_info(info_file, processed_info)
    
    if date_filter and date_filter.is_active():
        print(f"\nå‡¦ç†å®Œäº†: {processed_count}ä»¶, ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶, ãƒ•ã‚£ãƒ«ã‚¿é™¤å¤–: {filtered_count}ä»¶")
    else:
        print(f"\nå‡¦ç†å®Œäº†: {processed_count}ä»¶, ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶")
    return processed_count > 0


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¼šè©±ãƒ­ã‚°ã‚’Markdownã«å¤‰æ›')
    parser.add_argument('input_file', nargs='?', help='å…¥åŠ›ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•æ¤œç´¢ï¼‰')
    parser.add_argument('-o', '--output', help='å‡ºåŠ›Markdownãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--list', action='store_true', help='åˆ©ç”¨å¯èƒ½ãªãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€è¦§è¡¨ç¤º')
    parser.add_argument('--config', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--all', action='store_true', help='å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ¶é™ã‚’ç„¡è¦–ï¼‰')
    parser.add_argument('--force', action='store_true', help='æœªå¤‰æ›´ã§ã‚‚å¼·åˆ¶å‡¦ç†')
    parser.add_argument('--username', '-u', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼å')
    parser.add_argument('--start-date', help='é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰')
    parser.add_argument('--end-date', help='çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰')
    parser.add_argument('--set-date-range', action='store_true', help='æ—¥ä»˜ç¯„å›²ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜')
    
    args = parser.parse_args()
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = Config(args.config or 'log_converter_config.ini')
    
    # æ—¥ä»˜ç¯„å›²è¨­å®šã®ä¿å­˜
    if args.set_date_range:
        start_date = args.start_date or ''
        end_date = args.end_date or ''
        config.set_date_range(start_date, end_date)
        print(f"æ—¥ä»˜ç¯„å›²ã‚’è¨­å®šã—ã¾ã—ãŸ: {start_date} ã€œ {end_date}")
        return
    
    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ã®ä½œæˆ
    date_filter = None
    if args.start_date or args.end_date:
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ä½œæˆ
        date_filter = DateFilter(args.start_date, args.end_date)
        print(f"æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿: {args.start_date or 'é–‹å§‹æ—¥ãªã—'} ã€œ {args.end_date or 'çµ‚äº†æ—¥ãªã—'}")
    else:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿å–å¾—
        date_filter = config.get_date_filter()
        if date_filter and date_filter.is_active():
            start_str = date_filter.start_date.strftime('%Y-%m-%d') if date_filter.start_date else 'é–‹å§‹æ—¥ãªã—'
            end_str = date_filter.end_date.strftime('%Y-%m-%d') if date_filter.end_date else 'çµ‚äº†æ—¥ãªã—'
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ã‚’ä½¿ç”¨: {start_str} ã€œ {end_str}")
    
    # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
    info_file = Path('processed_files.json')
    processed_info = load_processed_files_info(info_file)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
    if args.list:
        files = find_log_files(config.get_log_directory())
        if files:
            print("åˆ©ç”¨å¯èƒ½ãªJSONLãƒ•ã‚¡ã‚¤ãƒ«:")
            for i, file in enumerate(files, 1):
                try:
                    rel_path = file.relative_to(config.get_log_directory())
                except ValueError:
                    rel_path = file
                file_size = file.stat().st_size
                mod_time = datetime.fromtimestamp(file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                status = "å‡¦ç†æ¸ˆã¿" if not should_process_file(file, processed_info) else "æœªå‡¦ç†"
                print(f"{i:2d}: {rel_path} ({file_size:,} bytes, æ›´æ–°: {mod_time}, {status})")
        else:
            print("JSONLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ±ºå®š
    if args.input_file:
        input_file = Path(args.input_file)
        if not input_file.exists():
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
            exit(1)
        
        # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        username = args.username or config.get_username()
        if args.output:
            output_file = Path(args.output)
        else:
            output_file = generate_output_filename(input_file, config.get_output_directory(), username)
        
        if not args.force and config.get_skip_unchanged() and not should_process_file(input_file, processed_info):
            print(f"ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªå¤‰æ›´ï¼‰: {input_file.name}")
            print("å¼·åˆ¶å‡¦ç†ã™ã‚‹å ´åˆã¯ --force ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
            return
        
        success = convert_log_to_markdown(input_file, output_file, date_filter)
        if success:
            processed_info[input_file.name] = {
                'mtime': input_file.stat().st_mtime,
                'output_file': str(output_file),
                'processed_at': datetime.now(timezone(timedelta(hours=9))).isoformat(),
                'date_filter': f"{date_filter.start_date}~{date_filter.end_date}" if date_filter and date_filter.is_active() else None
            }
            save_processed_files_info(info_file, processed_info)
        if not success:
            exit(1)
    else:
        # è‡ªå‹•æ¤œç´¢ãƒ»ä¸€æ‹¬å‡¦ç†
        files = find_log_files(config.get_log_directory())
        if not files:
            print("JSONLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            exit(1)
        
        # å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®åˆ¶é™
        if not args.all:
            max_files = config.get_max_files()
            files = files[:max_files]
            print(f"æœ€æ–°{len(files)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†å¯¾è±¡ã«ã—ã¾ã™ã€‚")
        
        # å¼·åˆ¶å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
        if args.force:
            processed_info = {}  # å‡¦ç†æ¸ˆã¿æƒ…å ±ã‚’ã‚¯ãƒªã‚¢
        
        success = process_multiple_files(files, config, processed_info, info_file, args.username, date_filter)
        if not success:
            exit(1)


if __name__ == "__main__":
    main()